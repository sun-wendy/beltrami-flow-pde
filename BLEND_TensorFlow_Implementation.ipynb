{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Code implementation references:\n",
        "\n",
        "1) The paper \"Beltrami Flow and Neural Diffusion on Graphs\" by Chamberlain et al.\n",
        "\n",
        "2) https://keras.io/examples/graph/gat_node_classification/"
      ],
      "metadata": {
        "id": "SV6rcJWnvYjZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYqN447EzAo2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras.layers as layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sklearn\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option(\"display.max_columns\", 6)\n",
        "pd.set_option(\"display.max_rows\", 6)\n",
        "np.random.seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsKmmGSwzDr4"
      },
      "outputs": [],
      "source": [
        "# Download Cora dataset\n",
        "zip_file = keras.utils.get_file(\n",
        "    fname=\"cora.tgz\",\n",
        "    origin=\"https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\",\n",
        "    extract=True,\n",
        ")\n",
        "\n",
        "data_dir = os.path.join(os.path.dirname(zip_file), \"cora\")\n",
        "\n",
        "# Get citations and papers\n",
        "citations = pd.read_csv(\n",
        "    os.path.join(data_dir, \"cora.cites\"),\n",
        "    sep=\"\\t\",\n",
        "    header=None,\n",
        "    names=[\"target\", \"source\"],\n",
        ")\n",
        "\n",
        "papers = pd.read_csv(\n",
        "    os.path.join(data_dir, \"cora.content\"),\n",
        "    sep=\"\\t\",\n",
        "    header=None,\n",
        "    names=[\"paper_id\"] + [f\"term_{idx}\" for idx in range(1433)] + [\"subject\"],\n",
        ")\n",
        "\n",
        "class_values = sorted(papers[\"subject\"].unique())\n",
        "class_idx = {name: id for id, name in enumerate(class_values)}\n",
        "paper_idx = {name: idx for idx, name in enumerate(sorted(papers[\"paper_id\"]))}\n",
        "\n",
        "papers[\"paper_id\"] = papers[\"paper_id\"].apply(lambda name: paper_idx[name])\n",
        "citations[\"source\"] = citations[\"source\"].apply(lambda name: paper_idx[name])\n",
        "citations[\"target\"] = citations[\"target\"].apply(lambda name: paper_idx[name])\n",
        "papers[\"subject\"] = papers[\"subject\"].apply(lambda value: class_idx[value])\n",
        "\n",
        "print(citations)\n",
        "print(papers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBFEuSiZzGIp"
      },
      "outputs": [],
      "source": [
        "# Obtain random indices\n",
        "random_indices = np.random.permutation(range(papers.shape[0]))\n",
        "\n",
        "# 50/50 split\n",
        "train_data = papers.iloc[random_indices[: len(random_indices) // 2]]\n",
        "test_data = papers.iloc[random_indices[len(random_indices) // 2 :]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JeoGzt2zJXb"
      },
      "outputs": [],
      "source": [
        "# Obtain paper indices which will be used to gather node states\n",
        "# from the graph later on when training the model\n",
        "train_indices = train_data[\"paper_id\"].to_numpy()\n",
        "test_indices = test_data[\"paper_id\"].to_numpy()\n",
        "\n",
        "# Obtain ground truth labels corresponding to each paper_id\n",
        "train_labels = train_data[\"subject\"].to_numpy()\n",
        "test_labels = test_data[\"subject\"].to_numpy()\n",
        "\n",
        "# Define nodes, edges, features, and joint (nodes & features) tensors\n",
        "nodes = tf.convert_to_tensor(papers.sort_values(\"paper_id\").iloc[:,0:1])\n",
        "edges = tf.convert_to_tensor(citations[[\"target\", \"source\"]])\n",
        "features = tf.convert_to_tensor(papers.sort_values(\"paper_id\").iloc[:, 1:-1])\n",
        "joint = tf.convert_to_tensor(np.hstack([nodes, features]))\n",
        "\n",
        "# Print shapes of the graph\n",
        "print(\"Nodes shape:\", nodes.shape)\n",
        "print(\"Edges shape:\", edges.shape)\n",
        "print(\"Node features shape:\", features.shape)\n",
        "print(\"Joint shape:\", joint.shape)\n",
        "print(nodes)\n",
        "print(edges)\n",
        "print(joint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F4SyxYs4BCtD"
      },
      "outputs": [],
      "source": [
        "# Prepare data for diffusivity calculation\n",
        "def data_prep(edges, features):\n",
        "  # Get the features of each of the two nodes that share one edge\n",
        "  feats_i = np.zeros((features.get_shape()[0], features.get_shape()[1]))\n",
        "  feats_j = np.zeros((features.get_shape()[0], features.get_shape()[1]))\n",
        "  feats_i_update = np.zeros((features.get_shape()[0], features.get_shape()[1]))\n",
        "  feats_j_update = np.zeros((features.get_shape()[0], features.get_shape()[1]))\n",
        "  edges_copy = edges.numpy()\n",
        "  nodes_i = edges_copy[:, 0:1]\n",
        "  nodes_j = edges_copy[:, 1:2]\n",
        "  for node_i, node_j in zip(nodes_i, nodes_j):\n",
        "    id_i = node_i[0]\n",
        "    id_j = node_j[0]\n",
        "    feat_i = features[id_i]\n",
        "    feat_j = features[id_j]\n",
        "    feats_i = np.vstack((feats_i, feat_i))\n",
        "    feats_i_update = feats_i[3:, :]\n",
        "    feats_j = np.vstack((feats_j, feat_j))\n",
        "    nodes_i = tf.convert_to_tensor(nodes_i)\n",
        "    nodes_j = tf.convert_to_tensor(nodes_j)\n",
        "    feats_i = tf.convert_to_tensor(feats_i)\n",
        "    feats_j = tf.convert_to_tensor(feats_j)\n",
        "  feats_i = feats_i[3:, :]\n",
        "  feats_j_update = feats_j[3:, :]\n",
        "  feats_i_update = tf.convert_to_tensor(feats_i_update)\n",
        "  feats_j_update = tf.convert_to_tensor(feats_j_update)\n",
        "  return feats_i_update, feats_j_update\n",
        "\n",
        "print(data_prep(edges, features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GUl5nJ4QEZJl"
      },
      "outputs": [],
      "source": [
        "joint = tf.cast(joint, dtype=tf.double)\n",
        "\n",
        "# Calculate diffusivity, and propagate it over the graph\n",
        "def forward_diffusion(edges, alpha=1):\n",
        "  nodes_i = edges[:, 0:1]\n",
        "  nodes_j = edges[:, 1:2]\n",
        "  feats_i_update, feats_j_update = data_prep(edges, features)\n",
        "  diff = tf.zeros([1, 1], dtype=tf.float64)\n",
        "\n",
        "  for node_i, node_j, feat_i, feat_j in zip(nodes_i, nodes_j, feats_i_update, feats_j_update):\n",
        "    node_i = tf.cast(node_i, dtype=tf.int32)\n",
        "    node_j = tf.cast(node_j, dtype=tf.int32)\n",
        "    one_node_feat = np.array([])\n",
        "    for f_i, f_j in zip(feat_i, feat_j):\n",
        "      f_i = tf.cast(f_i, dtype=tf.int32)\n",
        "      f_j = tf.cast(f_j, dtype=tf.int32)\n",
        "      grad = float((f_j - f_i) / (node_j - node_i))\n",
        "      one_node_feat = np.append(one_node_feat, grad)\n",
        "    one_node_feat = tf.convert_to_tensor(one_node_feat)\n",
        "    one_node_feat = tf.reshape(one_node_feat, [1, feats_i_update.get_shape()[1]])\n",
        "    diff_node = 1 + (alpha**2) * tf.linalg.matmul(one_node_feat, tf.transpose(one_node_feat))\n",
        "    diff_node = 1 / tf.sqrt(diff_node)\n",
        "    diff = tf.concat([diff, diff_node], 0)\n",
        "  \n",
        "  diff = np.delete(diff.numpy(), 0, 0)\n",
        "  diff = tf.convert_to_tensor(tf.math.l2_normalize(diff, 0))\n",
        "  return diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fJ7X6n7rz7Wr"
      },
      "outputs": [],
      "source": [
        "# Apply diffusion to positions and features one time\n",
        "class BeltramiLayer(layers.Layer):\n",
        "  def __init__(self, units, kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.edges = edges\n",
        "    self.units = units\n",
        "    self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
        "    self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    self.kernel = self.add_weight(shape=(input_shape[0][-1], self.units), trainable=True, \n",
        "                                  initializer=self.kernel_initializer, regularizer=self.kernel_regularizer, name=\"kerne\")\n",
        "    self.kernel_attention = self.add_weight(shape=(self.units*2, 1), trainable=True, \n",
        "                                            initializer=self.kernel_initializer, regularizer=self.kernel_regularizer, name=\"kerne_attention\")\n",
        "    self.built = True\n",
        "  \n",
        "  def call(self, edges, joint):\n",
        "    nodes_i = edges[:, 0:1]\n",
        "    nodes_j = edges[:, 1:2]\n",
        "\n",
        "    # Linearly transform nodes & features (joint tensor)\n",
        "    joint_transformed = tf.matmul(joint, self_kernel)\n",
        "\n",
        "    # Calculate and normalize diffusivity (equivalent of attention score)\n",
        "    diff_t = forward_diffusion(edges)\n",
        "\n",
        "    # Apply diffusivity to each node\n",
        "    joint_transposed = tf.transpose(joint_transformed)\n",
        "    joint_diffused = np.array([])\n",
        "    for all_nodes_feat in joint_transposed:\n",
        "      all_nodes_feat_after = np.array([])\n",
        "      for sing_node_feat, diff_one_feat in zip(all_nodes_feat, diff_t):\n",
        "        sing_node_feat_after = float(sing_node_feat) * float(diff_one_feat)\n",
        "        all_nodes_feat_after = all_nodes_feat_after.append(sing_node_feat_after)\n",
        "      joint_diffused = joint_diffused.append(joint_diffused, all_nodes_feat_after, axis=0)\n",
        "    # Nodes match back to edges - change edges\n",
        "    return joint_diffused"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ob4j1mYq4MXU"
      },
      "outputs": [],
      "source": [
        "# Build BLEND network\n",
        "class BLEND(keras.Model):\n",
        "  def __init__(self, edges, joint, input_dim, output_dim, hidden_units, num_layers, **kwargs):\n",
        "    super.__init__(**kwargs)\n",
        "    self.edges = edges\n",
        "    self.joint = joint\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.preprocess = layers.Dense(hidden_units, activation=\"relu\")\n",
        "    self.attention_layers = [BeltramiLayer(hidden_units) for _ in range(num_layers)]\n",
        "    self.output_layer = layers.Dense(output_dim)\n",
        "  \n",
        "  def call(self, joint):\n",
        "    diff_joint = self.preprocess(joint)\n",
        "\n",
        "    for attention_layer in self.attention_layers:\n",
        "      diff_joint = attention_layer([diff_joint, edges]) + diff_joint\n",
        "    \n",
        "    output = self.output_layer(diff_joint)\n",
        "    return output"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyMWavLVCy/KqTIlg67jCRKs"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}